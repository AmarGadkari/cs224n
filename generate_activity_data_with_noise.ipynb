{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hOA-7tvJ2DjB"
      },
      "outputs": [],
      "source": [
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jmP7MH-72FX0"
      },
      "outputs": [],
      "source": [
        "# Define your csv_columns list\n",
        "csv_columns = [\"Business Activity Description\", \"Business Activity Vendor\", \"Business Activity Cost USD\", \"Business Activity Comment\", \"2017 NAICS Title\"]\n",
        "\n",
        "file_folder = '/content/drive/My Drive/224_project/'\n",
        "\n",
        "# Specify Google Drive folder ID and file names\n",
        "folder_id = \"1RJDHqFP2jlMrWUsWP0KmsDwW8hPCzx_6\"\n",
        "\n",
        "total_file_name = 'sustainability_business_activities.csv'\n",
        "train_file_name = 'sustainability_business_activities_training.csv'\n",
        "test_file_name = 'sustainability_business_activities_test.csv'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb8_A1panZ7B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "def find_file_id_by_name(drive, folder_id, file_name):\n",
        "    \"\"\"Search for a file by name in the specified Google Drive folder.\"\"\"\n",
        "    query = f\"'{folder_id}' in parents and trashed=false and title='{file_name}'\"\n",
        "    file_list = drive.ListFile({'q': query}).GetList()\n",
        "    return file_list[0]['id'] if file_list else None\n",
        "\n",
        "# Assuming `gauth` and `drive` are already initialized\n",
        "# Your DataFrames: train_dataset and test_dataset\n",
        "\n",
        "def upload_dataframe(drive, folder_id, df, file_name):\n",
        "    # Convert DataFrame to CSV string\n",
        "    csv_string = df.to_csv(index=False)\n",
        "    content = StringIO(csv_string)\n",
        "\n",
        "    # Check if file exists\n",
        "    file_id = find_file_id_by_name(drive, folder_id, file_name)\n",
        "\n",
        "    if file_id:\n",
        "        # File exists, update the content\n",
        "        file = drive.CreateFile({'id': file_id})\n",
        "        file.SetContentString(csv_string)\n",
        "        file.Upload()\n",
        "        print(f\"Updated: {file_name}\")\n",
        "    else:\n",
        "        # File doesn't exist, create a new one\n",
        "        file = drive.CreateFile({'title': file_name, 'parents': [{'id': folder_id}]})\n",
        "        file.SetContentString(csv_string)\n",
        "        file.Upload()\n",
        "        print(f\"Created: {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLcasO5ggJGn"
      },
      "outputs": [],
      "source": [
        "# Define NAICS Titles and their associated business activities, vendors, and comments\n",
        "naics_info = {\n",
        "    \"Support Activities for Metal Mining\": {\n",
        "        \"activities\": {\n",
        "            \"Drilling services for zinc exploration\": {\n",
        "                \"vendors\": [\"ZincDrill Corp\", \"MetalExplorer Inc.\", \"DrillZinc Solutions\", \"ZincQuest Services\", \"ExploreZinc Co.\"],\n",
        "                \"comments\": [\n",
        "                    \"Precision drilling for accurate zinc location.\",\n",
        "                    \"Advanced geological analysis ensured.\",\n",
        "                    \"Minimized environmental footprint during exploration.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Environmental impact assessment for mining\": {\n",
        "                \"vendors\": [\"EcoImpact Assessors\", \"GreenMine Consultants\", \"SustainAssess Ltd.\", \"EcoMine Services\", \"EnviroImpact Analytics\"],\n",
        "                \"comments\": [\n",
        "                    \"Comprehensive ecosystem evaluation conducted.\",\n",
        "                    \"Strategies for water conservation implemented.\",\n",
        "                    \"Biodiversity preservation plans developed.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Ore transportation logistics\": {\n",
        "                \"vendors\": [\"HeavyLoad Transport\", \"OreMovers Inc.\", \"MetalFreight Co.\", \"RockShip Logistics\", \"MineCart Express\"],\n",
        "                \"comments\": [\n",
        "                    \"Efficient ore transport solutions.\",\n",
        "                    \"State-of-the-art logistics management.\",\n",
        "                    \"Eco-friendly transportation methods.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Mine site reclamation services\": {\n",
        "                \"vendors\": [\"EcoReclaim Ltd.\", \"LandRestore Co.\", \"ReGreening Services\", \"TerraHeal Solutions\", \"NatureMend Tech\"],\n",
        "                \"comments\": [\n",
        "                    \"Restoration of mining sites to natural state.\",\n",
        "                    \"Promoting biodiversity in reclaimed areas.\",\n",
        "                    \"Innovative land rehabilitation techniques.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Mineral processing consultancy\": {\n",
        "                \"vendors\": [\"MineralTech Advisors\", \"OreRefine Partners\", \"ProcessMax Consultants\", \"ExtractWell Analytics\", \"BeneficiatePro Services\"],\n",
        "                \"comments\": [\n",
        "                    \"Optimization of mineral processing operations.\",\n",
        "                    \"Implementation of cost-saving techniques.\",\n",
        "                    \"Maximizing ore recovery rates.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Mining equipment maintenance\": {\n",
        "                \"vendors\": [\"MineGear Service Co.\", \"DigTech Repair Solutions\", \"EquipFix Services\", \"HeavyDuty Maintenance\", \"DrillAndGrind Engineers\"],\n",
        "                \"comments\": [\n",
        "                    \"Ensuring operational efficiency and safety.\",\n",
        "                    \"Rapid response for equipment repairs.\",\n",
        "                    \"Comprehensive maintenance plans.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Safety training for mine workers\": {\n",
        "                \"vendors\": [\"SafeMine Training Academy\", \"MinerGuard Education Services\", \"SafetyFirst Workshops\", \"ProtectWell Training Programs\", \"HazardAware Courses\"],\n",
        "                \"comments\": [\n",
        "                    \"Empowering workers with safety knowledge.\",\n",
        "                    \"Compliance with mining safety regulations.\",\n",
        "                    \"Advanced risk management training.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Environmental monitoring services\": {\n",
        "                \"vendors\": [\"EcoWatch Services\", \"EnviroSense Monitoring\", \"GreenScan Analytics\", \"BioTrack Environmental\", \"NatureGuard Surveillance\"],\n",
        "                \"comments\": [\n",
        "                    \"Continuous environmental impact assessment.\",\n",
        "                    \"Utilizing advanced monitoring technologies.\",\n",
        "                    \"Data-driven environmental protection strategies.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Heavy machinery leasing\": {\n",
        "                \"vendors\": [\"MegaMach Leasing Co.\", \"HeavyLift Rental Services\", \"IronHorse Machinery\", \"PowerPlant Equipment Leasing\", \"ToughTrack Leases\"],\n",
        "                \"comments\": [\n",
        "                    \"Providing flexible leasing options.\",\n",
        "                    \"Access to latest mining machinery models.\",\n",
        "                    \"Cost-effective solutions for equipment needs.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Rock blasting and removal\": {\n",
        "                \"vendors\": [\"BlastAway Co.\", \"RockClear Services\", \"ExploTech Blasting\", \"RubbleManage Inc.\", \"DetonateRock Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"Precision blasting for site preparation.\",\n",
        "                    \"Safe removal of blasted rock material.\",\n",
        "                    \"Minimizing vibrations and environmental impact.\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"Sewage Treatment Facilities\": {\n",
        "        \"activities\": {\n",
        "            \"Wastewater treatment process optimization\": {\n",
        "                \"vendors\": [\"WaterClean Solutions\", \"PureFlow Tech\", \"EcoWater Systems\", \"AquaPurify Innovations\", \"CleanStream Technologies\"],\n",
        "                \"comments\": [\n",
        "                    \"Enhanced filtration techniques applied.\",\n",
        "                    \"Energy-efficient treatment methods introduced.\",\n",
        "                    \"Significant reduction in chemical usage achieved.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Sludge dewatering and disposal\": {\n",
        "                \"vendors\": [\"SludgeAway Technologies\", \"DryMatter Solutions\", \"EcoSludge Services\", \"Solidify Systems\", \"WasteNo Sludge Co.\"],\n",
        "                \"comments\": [\n",
        "                    \"Advanced centrifugation for moisture reduction.\",\n",
        "                    \"Eco-friendly disposal methods utilized.\",\n",
        "                    \"Conversion of sludge to renewable energy explored.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Chemical treatment of wastewater\": {\n",
        "                \"vendors\": [\"ChemClean Water Solutions\", \"AquaChem Tech\", \"PureTreat Chemicals\", \"WasteNeutralize Enterprises\", \"EcoChem Services\"],\n",
        "                \"comments\": [\n",
        "                    \"Advanced chemical treatments for purification.\",\n",
        "                    \"Reduction of harmful pathogens in effluent.\",\n",
        "                    \"Eco-friendly chemical usage policies.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Maintenance of treatment plant infrastructure\": {\n",
        "                \"vendors\": [\"AquaMaintain Ltd.\", \"PlantCare Engineering\", \"FacilityFix Services\", \"WaterWorks Maintenance\", \"SewageSustain Co.\"],\n",
        "                \"comments\": [\n",
        "                    \"Regular inspection and maintenance of facilities.\",\n",
        "                    \"Preventative maintenance to avoid downtime.\",\n",
        "                    \"Upgrading infrastructure for efficiency improvements.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Odor control in sewage facilities\": {\n",
        "                \"vendors\": [\"ScentGuard Technologies\", \"OdorShield Solutions\", \"FreshAir Environmental\", \"SmellBusters Co.\", \"AromaControl Systems\"],\n",
        "                \"comments\": [\n",
        "                    \"Implementing natural odor control measures.\",\n",
        "                    \"Advanced filtration systems to reduce smells.\",\n",
        "                    \"Improving community relations with odor management.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Grease and fat removal services\": {\n",
        "                \"vendors\": [\"GreaseGone Solutions\", \"FatFree Services\", \"ClearGrease Co.\", \"LipidLifters Inc.\", \"EcoFatClean Tech\"],\n",
        "                \"comments\": [\n",
        "                    \"Preventing blockages in sewage systems.\",\n",
        "                    \"Eco-friendly disposal of grease and fats.\",\n",
        "                    \"Maintaining cleanliness and flow efficiency.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Renewable energy generation from sewage\": {\n",
        "                \"vendors\": [\"BioEnergy Water Solutions\", \"RenewFlow Tech\", \"AquaPower Renewable\", \"WasteToWatt Co.\", \"EcoVolt Energy\"],\n",
        "                \"comments\": [\n",
        "                    \"Harnessing biogas from sewage treatment.\",\n",
        "                    \"Contributing to sustainability goals.\",\n",
        "                    \"Innovative energy recovery techniques.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Sewage system digital monitoring\": {\n",
        "                \"vendors\": [\"FlowSense Monitoring\", \"AquaTrack Technologies\", \"DigitalWater Watch\", \"EcoMonitor Solutions\", \"Waterwise Surveillance\"],\n",
        "                \"comments\": [\n",
        "                    \"Real-time data on sewage treatment operations.\",\n",
        "                    \"Predictive maintenance with digital tools.\",\n",
        "                    \"Enhancing system efficiency through technology.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Public health impact assessments\": {\n",
        "                \"vendors\": [\"HealthWater Consultancy\", \"PublicSafe Water Services\", \"EcoHealth Assessments\", \"WaterWell Public Health\", \"AquaHealth Analytics\"],\n",
        "                \"comments\": [\n",
        "                    \"Assessing the impact of sewage treatment on public health.\",\n",
        "                    \"Strategies for mitigating health risks.\",\n",
        "                    \"Collaboration with public health authorities.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Stormwater runoff management\": {\n",
        "                \"vendors\": [\"StormSafe Solutions\", \"RunoffGuard Co.\", \"RainFlow Management\", \"EcoStorm Services\", \"WaterRunoff Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"Innovative solutions for stormwater treatment.\",\n",
        "                    \"Reducing pollution from runoff.\",\n",
        "                    \"Improving water quality in local water bodies.\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"New Single-Family Housing Construction (except For-Sale Builders)\": {\n",
        "        \"activities\": {\n",
        "            \"Architectural design for family homes\": {\n",
        "                \"vendors\": [\"DesignBuild Architects\", \"EcoHomes Design Co.\", \"FutureNest Architecture\", \"GreenBlueprints Studio\", \"HarmonyDwell Designs\"],\n",
        "                \"comments\": [\n",
        "                    \"Custom designs to fit client lifestyles.\",\n",
        "                    \"Incorporation of green building practices.\",\n",
        "                    \"Focus on energy efficiency and sustainability.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Foundation and framing services\": {\n",
        "                \"vendors\": [\"SolidBase Constructors\", \"FrameRight Solutions\", \"EcoFoundation Systems\", \"SecureFrame Builders\", \"GroundUp Framing Co.\"],\n",
        "                \"comments\": [\n",
        "                    \"Utilizing durable and sustainable materials.\",\n",
        "                    \"Advanced techniques for structural integrity.\",\n",
        "                    \"Timely completion of foundational and framing stages.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Plumbing installation and fixtures\": {\n",
        "                \"vendors\": [\"FlowTech Plumbing\", \"AquaSafe Installations\", \"EcoWater Plumbing Co.\", \"PureFlow Systems\", \"Streamline Plumbing Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"High-quality fixtures to reduce water usage.\",\n",
        "                    \"Innovative solutions for water heating and recycling.\",\n",
        "                    \"Reliable installation ensuring long-term service.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Electrical wiring and smart home integration\": {\n",
        "                \"vendors\": [\"BrightFuture Electric\", \"SmartWatt Solutions\", \"EcoElectrics Co.\", \"PowerSafe Wiring\", \"InnovateHome Systems\"],\n",
        "                \"comments\": [\n",
        "                    \"Energy-efficient lighting and appliances.\",\n",
        "                    \"Integration of smart home technologies.\",\n",
        "                    \"Focus on safety and energy savings.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Roofing and insulation services\": {\n",
        "                \"vendors\": [\"EcoRoof Systems\", \"SecureCover Roofing\", \"WarmthWrap Insulation\", \"ShieldTop Roofs\", \"InsulateRight Services\"],\n",
        "                \"comments\": [\n",
        "                    \"Sustainable roofing materials for durability.\",\n",
        "                    \"Advanced insulation for climate control.\",\n",
        "                    \"Options for solar panel installation.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Landscaping and outdoor living spaces\": {\n",
        "                \"vendors\": [\"GreenEscape Landscaping\", \"OutdoorOasis Designs\", \"NatureNest Landscape Co.\", \"EcoYard Landscaping\", \"LivingSpaces Outdoors\"],\n",
        "                \"comments\": [\n",
        "                    \"Designs that complement natural surroundings.\",\n",
        "                    \"Creating functional and beautiful outdoor spaces.\",\n",
        "                    \"Incorporation of native plants and eco-friendly practices.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Interior finishing and painting\": {\n",
        "                \"vendors\": [\"InsideStyle Finishers\", \"ColorCraft Painters\", \"EcoInterior Coatings\", \"FinishLine Interiors\", \"BrightWalls Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"Use of low-VOC paints for indoor air quality.\",\n",
        "                    \"Attention to detail in finishing work.\",\n",
        "                    \"Custom interior designs to match homeowner preferences.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Flooring installation and treatments\": {\n",
        "                \"vendors\": [\"EcoFloors Installations\", \"GroundArt Flooring\", \"NatureWalk Surfaces\", \"StepWell Flooring Co.\", \"DuraFloor Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"Eco-friendly flooring options available.\",\n",
        "                    \"Durable treatments for high-traffic areas.\",\n",
        "                    \"Wide range of materials and finishes.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Window and door installation\": {\n",
        "                \"vendors\": [\"ClearView Windows\", \"SecureEntrance Doors\", \"EcoPane Solutions\", \"BrightAccess Installations\", \"OpenWay Doors & Windows\"],\n",
        "                \"comments\": [\n",
        "                    \"Energy-efficient windows for thermal control.\",\n",
        "                    \"Secure and durable doors for safety.\",\n",
        "                    \"Custom designs to enhance aesthetic appeal.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Heating, Ventilation, and Air Conditioning (HVAC) systems\": {\n",
        "                \"vendors\": [\"ClimateControl HVAC Co.\", \"EcoVent Systems\", \"PureAir Solutions\", \"ComfortZone HVAC\", \"ThermalTech Installations\"],\n",
        "                \"comments\": [\n",
        "                    \"High-efficiency systems for energy savings.\",\n",
        "                    \"Advanced air filtration for health and comfort.\",\n",
        "                    \"Smart systems for climate control and monitoring.\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"Timber Tract Operations\": {\n",
        "        \"activities\": {\n",
        "            \"Tree planting and reforestation\": {\n",
        "                \"vendors\": [\"GreenSeed Reforestation\", \"EcoGrow Forestry\", \"TreeRevive Operations\", \"ForestRenew Planters\", \"SaplingStart Co.\"],\n",
        "                \"comments\": [\n",
        "                    \"Ensuring sustainability of timber resources.\",\n",
        "                    \"Specializing in native species to promote biodiversity.\",\n",
        "                    \"Utilizing GPS mapping for optimal planting strategies.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Timber harvesting operations\": {\n",
        "                \"vendors\": [\"LogCutters Inc.\", \"TimberYield Harvesting\", \"WoodFell Solutions\", \"ForestExtract Co.\", \"ClearCut Logging\"],\n",
        "                \"comments\": [\n",
        "                    \"Precision cutting to minimize waste.\",\n",
        "                    \"Adhering to sustainable harvest practices.\",\n",
        "                    \"Implementing low-impact logging techniques.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Forest management and conservation\": {\n",
        "                \"vendors\": [\"EcoForest Management\", \"GreenCanopy Consultants\", \"BioDiverse Forestry\", \"ConservForest Services\", \"SustainWood Group\"],\n",
        "                \"comments\": [\n",
        "                    \"Balancing timber production with ecosystem health.\",\n",
        "                    \"Developing long-term forest management plans.\",\n",
        "                    \"Monitoring health and growth of forest tracts.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Pest and disease control\": {\n",
        "                \"vendors\": [\"PestAway TimberCare\", \"TreeGuardians Co.\", \"ForestShield Services\", \"EcoPest Forestry\", \"TimberHealth Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"Employing environmentally friendly pest control methods.\",\n",
        "                    \"Regular monitoring for early disease detection.\",\n",
        "                    \"Implementing integrated pest management (IPM) strategies.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Timber valuation and appraisal\": {\n",
        "                \"vendors\": [\"WoodWorth Appraisals\", \"TimberValue Consultants\", \"EstateLogs Valuation\", \"TreeEquity Services\", \"LumberGrade Assessors\"],\n",
        "                \"comments\": [\n",
        "                    \"Accurate valuation for sales and acquisitions.\",\n",
        "                    \"Expert appraisals based on market trends.\",\n",
        "                    \"Providing comprehensive forestry investment analysis.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Road construction and maintenance for logging\": {\n",
        "                \"vendors\": [\"LogPath Engineers\", \"ForestRoads Construction\", \"TimberTrail Co.\", \"EcoAccess Routes\", \"WoodWay Builders\"],\n",
        "                \"comments\": [\n",
        "                    \"Building access roads with minimal environmental impact.\",\n",
        "                    \"Maintaining roads for safety and sustainability.\",\n",
        "                    \"Utilizing erosion control measures in road design.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Timber marketing and sales\": {\n",
        "                \"vendors\": [\"WoodMarket Solutions\", \"LogSales Network\", \"TimberTrade Co.\", \"ForestProducts Exchange\", \"EcoTimber Sales\"],\n",
        "                \"comments\": [\n",
        "                    \"Connecting sellers with global markets.\",\n",
        "                    \"Promoting sustainable timber products.\",\n",
        "                    \"Implementing traceability for timber origin.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Wildlife habitat management\": {\n",
        "                \"vendors\": [\"WildHabitat Forestry\", \"EcoFauna Management\", \"BioHaven Wildlife Services\", \"NatureBalance Co.\", \"HabitatHarmony Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"Integrating wildlife conservation into timber operations.\",\n",
        "                    \"Creating buffer zones to protect sensitive species.\",\n",
        "                    \"Monitoring biodiversity as a key management metric.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Water resource management on timber lands\": {\n",
        "                \"vendors\": [\"AquaForest Management\", \"StreamGuard Services\", \"EcoWatershed Co.\", \"TimberSpring WaterCare\", \"ForestRivers Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"Protecting water quality through best management practices.\",\n",
        "                    \"Restoring stream and river habitats affected by logging.\",\n",
        "                    \"Implementing rainwater harvesting for drought resilience.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Fire prevention and control measures\": {\n",
        "                \"vendors\": [\"FlameWard Forestry\", \"FireBreak Solutions\", \"EcoFireGuard Co.\", \"BlazeControl Services\", \"WildfirePrevent Consultants\"],\n",
        "                \"comments\": [\n",
        "                    \"Strategic creation of firebreaks and buffer zones.\",\n",
        "                    \"Utilizing controlled burns for underbrush management.\",\n",
        "                    \"Deploying early detection systems for rapid response.\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"Uranium-Radium-Vanadium Ore Mining\": {\n",
        "        \"activities\": {\n",
        "            \"Uranium ore extraction\": {\n",
        "                \"vendors\": [\"UraniumExtract Ltd.\", \"EcoUranium Solutions\", \"PureUranium Co.\", \"RadMine Operations\", \"VanadoUranium Group\"],\n",
        "                \"comments\": [\n",
        "                    \"High-grade uranium extraction with minimal environmental impact.\",\n",
        "                    \"Implementing advanced safety measures for workers.\",\n",
        "                    \"Utilizing innovative technologies for efficient ore processing.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Radium isolation processes\": {\n",
        "                \"vendors\": [\"RadiumTech Innovations\", \"EcoRad Solutions\", \"RadPurity Extractors\", \"IsolateRadium Co.\", \"RadiantRadium Services\"],\n",
        "                \"comments\": [\n",
        "                    \"Specialized techniques for radium isolation from ore.\",\n",
        "                    \"Ensuring environmental safety in radium processing.\",\n",
        "                    \"Conducting thorough radiation safety assessments.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Vanadium mining and processing\": {\n",
        "                \"vendors\": [\"VanadiumValley Co.\", \"EcoVan Mining\", \"VanaTech Processing\", \"PureVan Extracts\", \"InnoVanadium Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"Extracting vanadium with high purity levels.\",\n",
        "                    \"Focusing on sustainable mining practices.\",\n",
        "                    \"Applying state-of-the-art processing technology.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Ore crushing and milling\": {\n",
        "                \"vendors\": [\"CrushMill Ore Services\", \"EcoCrush Technologies\", \"MegaMillers Ltd.\", \"OreGrind Solutions\", \"FineCrush Co.\"],\n",
        "                \"comments\": [\n",
        "                    \"Efficient ore crushing for optimal extraction.\",\n",
        "                    \"Reducing energy consumption in milling operations.\",\n",
        "                    \"Innovating in dust control techniques during processing.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Leaching process for uranium extraction\": {\n",
        "                \"vendors\": [\"LeachPro Uranium Services\", \"EcoLeach Solutions\", \"UraLeach Tech\", \"PureExtract Leaching\", \"LeachWell Uranium\"],\n",
        "                \"comments\": [\n",
        "                    \"Maximizing uranium yield through advanced leaching.\",\n",
        "                    \"Minimizing environmental footprint of leaching operations.\",\n",
        "                    \"Enhancing safety protocols in chemical leaching processes.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Radiation safety and environmental monitoring\": {\n",
        "                \"vendors\": [\"RadSafe Monitoring Co.\", \"EnviroRad Services\", \"SafeRad Technologies\", \"EcoMonitor Radiation\", \"RadGuard Analytics\"],\n",
        "                \"comments\": [\n",
        "                    \"Comprehensive radiation safety measures in place.\",\n",
        "                    \"Continuous environmental monitoring for public safety.\",\n",
        "                    \"Implementing best practices in radiation control.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Tailings management and disposal\": {\n",
        "                \"vendors\": [\"TailingsCare Solutions\", \"EcoTails Management\", \"SafeDisposal Systems\", \"TailingsTech Co.\", \"EnviroTailings Services\"],\n",
        "                \"comments\": [\n",
        "                    \"Innovative tailings management for sustainability.\",\n",
        "                    \"Implementing secure disposal methods.\",\n",
        "                    \"Focus on reducing tailings pond footprint.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Water treatment in mining operations\": {\n",
        "                \"vendors\": [\"AquaMine Solutions\", \"CleanWater Mining Co.\", \"EcoWater Treatment\", \"WaterPure Systems\", \"MineWaterTech\"],\n",
        "                \"comments\": [\n",
        "                    \"Advanced water treatment for mining effluents.\",\n",
        "                    \"Ensuring water quality exceeds environmental standards.\",\n",
        "                    \"Recycling and reusing water within mining operations.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Transport and logistics for mined ore\": {\n",
        "                \"vendors\": [\"OreTrans Logistics\", \"EcoTrans Mining Co.\", \"SafeCargo Solutions\", \"MineMovers Transport\", \"RadVan Logistics\"],\n",
        "                \"comments\": [\n",
        "                    \"Efficient transport solutions for uranium ore.\",\n",
        "                    \"Implementing eco-friendly logistics practices.\",\n",
        "                    \"Enhanced safety measures for radioactive material transport.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Mine reclamation and ecosystem restoration\": {\n",
        "                \"vendors\": [\"ReclaimEarth Services\", \"EcoRestore Mining\", \"GreenMine Reclamation\", \"RestoreLand Co.\", \"MineHeal Environmental\"],\n",
        "                \"comments\": [\n",
        "                    \"Restoring mined lands to their natural state.\",\n",
        "                    \"Promoting biodiversity in mine reclamation projects.\",\n",
        "                    \"Utilizing native plants in ecosystem restoration.\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"Automobile Driving Schools\": {\n",
        "        \"activities\": {\n",
        "            \"Beginner driving lessons\": {\n",
        "                \"vendors\": [\"StartRight Driving School\", \"FirstGear Lessons\", \"NewDriver Academy\", \"RoadBasics School\", \"DriveStart Educators\"],\n",
        "                \"comments\": [\n",
        "                    \"Tailored to new drivers for a solid foundation.\",\n",
        "                    \"Emphasizes safety and road awareness from day one.\",\n",
        "                    \"Instructors certified with a focus on patience and clarity.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Advanced driving techniques\": {\n",
        "                \"vendors\": [\"ProDrive Techniques\", \"AdvancedWheel School\", \"SkillShift Academy\", \"EliteDrivers Course\", \"PrecisionPilots Lessons\"],\n",
        "                \"comments\": [\n",
        "                    \"Covers defensive driving, evasive maneuvers, and more.\",\n",
        "                    \"Designed for experienced drivers to enhance skills.\",\n",
        "                    \"Utilizes simulation and on-road training for mastery.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Defensive driving courses\": {\n",
        "                \"vendors\": [\"SafeGuard Driving\", \"DefendDrive School\", \"ShieldOn Driving Academy\", \"FortressWheel Training\", \"DefensiveRoads School\"],\n",
        "                \"comments\": [\n",
        "                    \"Focuses on anticipating and avoiding road hazards.\",\n",
        "                    \"Incorporates latest safety techniques and technologies.\",\n",
        "                    \"Reduces risk of accidents through proactive training.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Driving test preparation\": {\n",
        "                \"vendors\": [\"TestReady Driving School\", \"PassFirst Go\", \"LicenseQuest Prep\", \"DriveTest Success Academy\", \"ExamGear Drivers\"],\n",
        "                \"comments\": [\n",
        "                    \"Comprehensive review and mock tests for confidence.\",\n",
        "                    \"Highlights common test pitfalls and how to avoid them.\",\n",
        "                    \"Personalized coaching based on student's weaknesses.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Eco-driving lessons\": {\n",
        "                \"vendors\": [\"EcoWheel Education\", \"GreenDrive School\", \"SustainaRide Lessons\", \"EcoPilot Academy\", \"CleanDrive Instructors\"],\n",
        "                \"comments\": [\n",
        "                    \"Teaches fuel-efficient driving habits.\",\n",
        "                    \"Contributes to environmental protection and cost savings.\",\n",
        "                    \"Incorporates hybrid and electric vehicle training.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Vehicle maintenance workshops\": {\n",
        "                \"vendors\": [\"AutoUpkeep Workshop\", \"MaintainMasters Class\", \"CarCare Clinic\", \"VehicleVitals Lessons\", \"TuneUp Teach\"],\n",
        "                \"comments\": [\n",
        "                    \"Hands-on learning for basic vehicle upkeep and emergency repairs.\",\n",
        "                    \"Empowers drivers with knowledge to minimize maintenance costs.\",\n",
        "                    \"Courses tailored for different vehicle types and models.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Motorcycle driving lessons\": {\n",
        "                \"vendors\": [\"TwoWheels Training Academy\", \"MotoLearn School\", \"BikeBasics Instructors\", \"CycleSafe Lessons\", \"RiderCraft Education\"],\n",
        "                \"comments\": [\n",
        "                    \"Specialized curriculum for aspiring motorcyclists.\",\n",
        "                    \"Emphasizes balance, control, and road safety.\",\n",
        "                    \"Includes gear selection and maintenance advice.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Commercial driving license (CDL) training\": {\n",
        "                \"vendors\": [\"CDLPro Academy\", \"HeavyHaulers School\", \"TruckMasters Training\", \"BigRig Educators\", \"CommercialDrivers Course\"],\n",
        "                \"comments\": [\n",
        "                    \"Prepares students for CDL exams with intensive training.\",\n",
        "                    \"Covers commercial vehicle laws, log keeping, and cargo safety.\",\n",
        "                    \"Includes behind-the-wheel practice with various truck types.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Teen driving safety programs\": {\n",
        "                \"vendors\": [\"YouthDrive Initiative\", \"TeenWheelers School\", \"SafeStart Young Drivers\", \"NextGen Drivers Academy\", \"GuardianRoad Teens\"],\n",
        "                \"comments\": [\n",
        "                    \"Designed to instill responsible driving habits early.\",\n",
        "                    \"Interactive sessions with emphasis on peer influence.\",\n",
        "                    \"Partners with schools and communities for outreach.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Driver rehabilitation and retraining\": {\n",
        "                \"vendors\": [\"DriveAgain Center\", \"WheelRecovery Services\", \"BackOnRoad Academy\", \"ReDrive Clinic\", \"SteerClear Program\"],\n",
        "                \"comments\": [\n",
        "                    \"Support for drivers recovering from injuries or disabilities.\",\n",
        "                    \"Adapts teaching methods and vehicles to individual needs.\",\n",
        "                    \"Focuses on restoring confidence and independence on the road.\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"Offices of Dentists\": {\n",
        "        \"activities\": {\n",
        "            \"General dental check-ups\": {\n",
        "                \"vendors\": [\"DentalCare Associates\", \"BrightSmile Clinics\", \"HealthyTeeth Dental\", \"OralWellness Providers\", \"SmileFirst Services\"],\n",
        "                \"comments\": [\n",
        "                    \"Emphasis on preventative care and oral hygiene.\",\n",
        "                    \"Routine examinations to maintain dental health.\",\n",
        "                    \"Utilizing the latest diagnostic technology for comprehensive check-ups.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Cosmetic dentistry services\": {\n",
        "                \"vendors\": [\"AestheticDental Arts\", \"CosmoSmile Dental Studio\", \"BrightenDent Aesthetics\", \"SmileDesign Experts\", \"GlamourSmiles Clinic\"],\n",
        "                \"comments\": [\n",
        "                    \"Specializing in smile makeovers and aesthetic improvements.\",\n",
        "                    \"Offering a range of services from whitening to veneers.\",\n",
        "                    \"Personalized cosmetic plans to enhance patients' smiles.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Orthodontic treatments\": {\n",
        "                \"vendors\": [\"AlignOrtho Care\", \"BraceBright Orthodontics\", \"StraightPath Dental\", \"HarmonyOrtho Solutions\", \"PerfectSmile Braces\"],\n",
        "                \"comments\": [\n",
        "                    \"Expertise in teeth alignment and bite correction.\",\n",
        "                    \"Utilizing modern braces and clear aligner technologies.\",\n",
        "                    \"Tailored orthodontic plans for all age groups.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Pediatric dentistry\": {\n",
        "                \"vendors\": [\"LittleSmiles Pediatric\", \"KidsDental Zone\", \"TinyTeeth Specialists\", \"YouthfulBites Dental\", \"ChildCare Dentistry\"],\n",
        "                \"comments\": [\n",
        "                    \"Dedicated care for children's dental health.\",\n",
        "                    \"Creating a friendly and reassuring environment for young patients.\",\n",
        "                    \"Focusing on preventive care and oral health education.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Periodontal disease treatment\": {\n",
        "                \"vendors\": [\"GumGuardians Clinic\", \"PerioProtect Services\", \"DeepClean Dental\", \"GumHealth Specialists\", \"BeneathTheGums Care\"],\n",
        "                \"comments\": [\n",
        "                    \"Advanced treatment options for gum disease.\",\n",
        "                    \"Personalized care plans to halt disease progression.\",\n",
        "                    \"Emphasis on minimally invasive procedures for gum health.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Dental implant services\": {\n",
        "                \"vendors\": [\"ImplantInnovations Dental\", \"AnchorDent Implants\", \"FoundationTeeth Solutions\", \"PermanentSmiles Clinic\", \"ToothRoot Systems\"],\n",
        "                \"comments\": [\n",
        "                    \"State-of-the-art dental implant solutions.\",\n",
        "                    \"Restoring functionality with a natural look and feel.\",\n",
        "                    \"Comprehensive care from consultation to post-operative follow-up.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Emergency dental services\": {\n",
        "                \"vendors\": [\"RapidRelief Dental Care\", \"EmergencyDent Assist\", \"24Hour Dental Clinic\", \"UrgentCare ToothSavers\", \"ImmediateHelp Dentists\"],\n",
        "                \"comments\": [\n",
        "                    \"Prompt care for dental emergencies and injuries.\",\n",
        "                    \"Available around the clock for urgent dental needs.\",\n",
        "                    \"Equipped to handle a wide range of dental emergencies.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Dental hygiene services\": {\n",
        "                \"vendors\": [\"CleanBite Hygiene\", \"FreshMouth Dental Care\", \"HygieneMasters Clinic\", \"PlaqueFighters Services\", \"BrightGleam Cleanings\"],\n",
        "                \"comments\": [\n",
        "                    \"Professional cleaning to prevent cavities and gum disease.\",\n",
        "                    \"Educating patients on effective oral hygiene practices.\",\n",
        "                    \"Utilizing gentle techniques for a comfortable experience.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Endodontic (root canal) therapy\": {\n",
        "                \"vendors\": [\"RootCare Specialists\", \"EndoHeal Dental\", \"PainFreeRoots Clinic\", \"CanalCure Endodontics\", \"InsideTooth Care\"],\n",
        "                \"comments\": [\n",
        "                    \"Expert care for root canal therapy and tooth pain relief.\",\n",
        "                    \"Utilizing advanced techniques for successful outcomes.\",\n",
        "                    \"Focus on patient comfort and preserving natural teeth.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Dental X-ray and imaging services\": {\n",
        "                \"vendors\": [\"ImageDent Diagnostics\", \"RadiantSmile Imaging\", \"XrayVision Dental\", \"OralScan Services\", \"DentoGraphix Clinic\"],\n",
        "                \"comments\": [\n",
        "                    \"High-definition imaging for accurate diagnostics.\",\n",
        "                    \"Minimally invasive X-ray techniques for patient safety.\",\n",
        "                    \"Comprehensive imaging services to support dental treatments.\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"Kidney Dialysis Centers\": {\n",
        "        \"activities\": {\n",
        "            \"Hemodialysis treatment\": {\n",
        "                \"vendors\": [\"CleanFilter Dialysis\", \"HemoCare Services\", \"PureBlood Solutions\", \"LifeStream Dialysis\", \"RenalTech Centers\"],\n",
        "                \"comments\": [\n",
        "                    \"State-of-the-art hemodialysis equipment for efficient blood filtering.\",\n",
        "                    \"Personalized care plans tailored to individual patient needs.\",\n",
        "                    \"Continuous monitoring and adjustment for optimal treatment outcomes.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Peritoneal dialysis support\": {\n",
        "                \"vendors\": [\"HomeDialysis Plus\", \"PeriCare Solutions\", \"InnerCleanse Therapy\", \"GentleDialysis Supplies\", \"StayPure Systems\"],\n",
        "                \"comments\": [\n",
        "                    \"Comprehensive support for at-home peritoneal dialysis patients.\",\n",
        "                    \"Training and ongoing assistance for patients and families.\",\n",
        "                    \"Supply of high-quality dialysis fluids and equipment.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Kidney health education\": {\n",
        "                \"vendors\": [\"RenalEd Partners\", \"KidneyWise Academy\", \"HealthStream Education\", \"NephroKnow Institute\", \"RenalAware Program\"],\n",
        "                \"comments\": [\n",
        "                    \"Empowering patients with knowledge about kidney health maintenance.\",\n",
        "                    \"Workshops on diet, lifestyle, and disease management for renal patients.\",\n",
        "                    \"Collaborations with healthcare professionals for comprehensive education.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Dialysis access management\": {\n",
        "                \"vendors\": [\"AccessPoint Care\", \"VascularAccess Solutions\", \"FlowGuard Management\", \"DialyAccess Clinics\", \"VeinCare Dialysis Services\"],\n",
        "                \"comments\": [\n",
        "                    \"Expert care in creating and maintaining dialysis access sites.\",\n",
        "                    \"Minimally invasive procedures to maximize treatment efficacy.\",\n",
        "                    \"Regular assessments to ensure access site health and function.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Transplant coordination services\": {\n",
        "                \"vendors\": [\"TransplantLink Coordination\", \"NewLife Transplant Services\", \"MatchOrgan Network\", \"HopeTransplant Connect\", \"LifeGift Transplant Support\"],\n",
        "                \"comments\": [\n",
        "                    \"Guidance through the kidney transplant process.\",\n",
        "                    \"Support for patients on the transplant waiting list.\",\n",
        "                    \"Collaboration with transplant centers for seamless patient care.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Nutritional counseling for dialysis patients\": {\n",
        "                \"vendors\": [\"NutriRenal Advisors\", \"DietWellness Renal\", \"KidneyNutri Care\", \"BalancedBites Counseling\", \"RenalDiet Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"Tailored dietary plans to support kidney health and dialysis treatment.\",\n",
        "                    \"Professional advice on managing fluid and mineral intake.\",\n",
        "                    \"Regular follow-ups to adjust dietary plans as needed.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Psychological support services\": {\n",
        "                \"vendors\": [\"MindRenal Support\", \"DialyzeMind Wellness\", \"RenalSpirit Counseling\", \"PsycheRenal Health\", \"EmbraceWellness Therapy\"],\n",
        "                \"comments\": [\n",
        "                    \"Emotional and psychological support tailored for renal patients.\",\n",
        "                    \"Counseling services to help cope with the challenges of chronic kidney disease.\",\n",
        "                    \"Group therapy sessions and peer support networks.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Anemia management in dialysis\": {\n",
        "                \"vendors\": [\"HemoBoost Therapies\", \"IronFlow Treatments\", \"AnemiaCare Dialysis Support\", \"BloodHealth Solutions\", \"VitalHem Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"Comprehensive anemia management protocols for dialysis patients.\",\n",
        "                    \"Monitoring and treatment with iron supplements and EPO therapy.\",\n",
        "                    \"Individualized care plans to address the root causes of anemia.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Fluid management technology\": {\n",
        "                \"vendors\": [\"HydraBalance Tech\", \"FluidWise Systems\", \"AquaControl Dialysis\", \"FlowRegulate Innovations\", \"Liquidus Management Devices\"],\n",
        "                \"comments\": [\n",
        "                    \"Advanced technologies for precise fluid removal during dialysis.\",\n",
        "                    \"Customizable treatment settings to meet patient-specific needs.\",\n",
        "                    \"Continuous innovation in fluid management for enhanced patient safety.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Infection prevention and control\": {\n",
        "                \"vendors\": [\"CleanDialysis Environments\", \"InfectoGuard Protocols\", \"SteriRenal Systems\", \"SafeDialyze Practices\", \"PathoShield Measures\"],\n",
        "                \"comments\": [\n",
        "                    \"Rigorous infection control measures to ensure patient safety.\",\n",
        "                    \"Implementation of CDC guidelines in all treatment and common areas.\",\n",
        "                    \"Regular training for staff on hygiene and infection prevention.\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"Historical Sites\": {\n",
        "        \"activities\": {\n",
        "            \"Preservation and restoration projects\": {\n",
        "                \"vendors\": [\"HeritagePreserve Constructors\", \"PastRenew Partners\", \"EraRestore Solutions\", \"TimeKeepers Restoration\", \"LegacyBuilders Co.\"],\n",
        "                \"comments\": [\n",
        "                    \"Dedicated to maintaining the authenticity of historical structures.\",\n",
        "                    \"Utilizing traditional materials and techniques for restoration.\",\n",
        "                    \"Collaborating with historians to ensure historical accuracy.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Educational programs and tours\": {\n",
        "                \"vendors\": [\"HistoryWalks Education\", \"TimeTales Tours\", \"PastPaths Guides\", \"EduJourneys Historical\", \"HeritageExplorers Co.\"],\n",
        "                \"comments\": [\n",
        "                    \"Engaging and informative tours for all age groups.\",\n",
        "                    \"Customized educational programs for schools and universities.\",\n",
        "                    \"Utilizing technology to enhance the learning experience.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Exhibit design and installation\": {\n",
        "                \"vendors\": [\"EraDisplays Solutions\", \"ExhibitPast Creators\", \"TimelineDesigns Co.\", \"HistoriCraft Installations\", \"ShowcaseHistory Partners\"],\n",
        "                \"comments\": [\n",
        "                    \"Creating immersive and interactive exhibits.\",\n",
        "                    \"Highlighting significant historical events and figures.\",\n",
        "                    \"Incorporating multimedia elements for dynamic presentations.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Conservation research and studies\": {\n",
        "                \"vendors\": [\"HeritageResearch Lab\", \"ConservaStudies Group\", \"AncientAnalytics Co.\", \"PastProbe Researchers\", \"TimeTested Science\"],\n",
        "                \"comments\": [\n",
        "                    \"Advanced research for preserving historical artifacts.\",\n",
        "                    \"Developing new methods for long-term conservation.\",\n",
        "                    \"Collaborating with academic institutions for comprehensive studies.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Cultural heritage events\": {\n",
        "                \"vendors\": [\"CulturaFest Organizers\", \"HeritageHappenings Events\", \"EpochEvents Planning\", \"AncestralCelebrations Co.\", \"TraditionsAlive LLC\"],\n",
        "                \"comments\": [\n",
        "                    \"Showcasing traditional crafts, music, and dances.\",\n",
        "                    \"Promoting understanding and appreciation of cultural diversity.\",\n",
        "                    \"Annual events to celebrate and preserve local heritage.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Archaeological excavation support\": {\n",
        "                \"vendors\": [\"DigDeep Archaeology\", \"PastLayers Excavations\", \"ArtifactFinders Co.\", \"HistoryUnearthed Services\", \"GroundStories LLC\"],\n",
        "                \"comments\": [\n",
        "                    \"Expert teams for sensitive archaeological digs.\",\n",
        "                    \"Uncovering and documenting historical artifacts.\",\n",
        "                    \"Working closely with historians and archaeologists for site preservation.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Historical documentation and archiving\": {\n",
        "                \"vendors\": [\"ArchiveMasters Services\", \"EraDocs Solutions\", \"PastRecords Co.\", \"HeritageFiles Organization\", \"TimeCapsule Archives\"],\n",
        "                \"comments\": [\n",
        "                    \"Digitizing and preserving historical documents.\",\n",
        "                    \"Creating accessible archives for research and education.\",\n",
        "                    \"Ensuring the longevity of valuable historical records.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Landscape restoration and maintenance\": {\n",
        "                \"vendors\": [\"HeritageGrounds Landscaping\", \"HistoricSites Gardening\", \"PastScapes Management\", \"EraGardens Care\", \"LegacyLawns Services\"],\n",
        "                \"comments\": [\n",
        "                    \"Restoring historical site landscapes to their original state.\",\n",
        "                    \"Maintaining the natural beauty and historical integrity of sites.\",\n",
        "                    \"Employing eco-friendly practices for sustainable site management.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Historical site marketing and promotion\": {\n",
        "                \"vendors\": [\"HistoryHighlights Marketing\", \"PastPromos Co.\", \"EraAttractions Advertising\", \"HeritageBuzz Solutions\", \"LegacyLure Campaigns\"],\n",
        "                \"comments\": [\n",
        "                    \"Raising awareness and interest in historical sites.\",\n",
        "                    \"Developing engaging marketing campaigns for increased visitation.\",\n",
        "                    \"Utilizing social media to reach a broader audience.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Visitor services and amenities\": {\n",
        "                \"vendors\": [\"TimeTraveler Amenities\", \"VisitorVault Services\", \"HeritageHosts Co.\", \"PastComforts Facilities\", \"HistoryHaven Concessions\"],\n",
        "                \"comments\": [\n",
        "                    \"Enhancing the visitor experience with quality amenities.\",\n",
        "                    \"Providing informative and friendly services for guests.\",\n",
        "                    \"Offering refreshments and merchandise inspired by historical themes.\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"Bowling Centers\": {\n",
        "        \"activities\": {\n",
        "            \"League play organization\": {\n",
        "                \"vendors\": [\"StrikeMasters Leagues\", \"PinChampions Coordinators\", \"BowlLeague Creators\", \"AlleyChamps Organizers\", \"KingpinLeagues Services\"],\n",
        "                \"comments\": [\n",
        "                    \"Hosting competitive leagues for all skill levels.\",\n",
        "                    \"Creating a community atmosphere with regular play.\",\n",
        "                    \"Organizing seasonal and themed bowling tournaments.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Youth bowling programs\": {\n",
        "                \"vendors\": [\"JuniorRollers Academy\", \"KidsBowl Club\", \"FutureStrikers Youth\", \"PinPals Junior Leagues\", \"LittleBowler Coaching\"],\n",
        "                \"comments\": [\n",
        "                    \"Introducing children to the sport in a fun, supportive environment.\",\n",
        "                    \"Teaching fundamentals and sportsmanship through structured programs.\",\n",
        "                    \"Hosting family-friendly events and youth tournaments.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Bowling equipment sales and rental\": {\n",
        "                \"vendors\": [\"ProShop Gear\", \"StrikeZone Equipment\", \"AlleyEquip Sales\", \"BowlEssentials Store\", \"PinGear Rentals\"],\n",
        "                \"comments\": [\n",
        "                    \"Offering a wide range of bowling balls, shoes, and accessories.\",\n",
        "                    \"Providing expert advice for equipment selection.\",\n",
        "                    \"Featuring the latest technology in bowling gear for optimal performance.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Corporate and group events\": {\n",
        "                \"vendors\": [\"GroupBowl Events\", \"CorporateStrikes Planners\", \"TeamPin Gatherings\", \"EventBowl Solutions\", \"StrikeTeam Organizing\"],\n",
        "                \"comments\": [\n",
        "                    \"Tailoring packages for team-building and corporate outings.\",\n",
        "                    \"Offering private lanes and meeting spaces for groups.\",\n",
        "                    \"Customizing events with catering and entertainment options.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Bowling instruction and coaching\": {\n",
        "                \"vendors\": [\"BowlCoach Institute\", \"StrikeSkill Trainers\", \"PinPros Lessons\", \"AlleyMasters Coaching\", \"FrameUp Instruction\"],\n",
        "                \"comments\": [\n",
        "                    \"Improving skills through personalized coaching sessions.\",\n",
        "                    \"Catering to both beginners and advanced players.\",\n",
        "                    \"Utilizing video analysis for technique improvement.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Food and beverage services\": {\n",
        "                \"vendors\": [\"LaneSnacks Cafe\", \"PinBites Grill\", \"BowlBar Beverages\", \"StrikeEats Restaurant\", \"GutterGourmet Catering\"],\n",
        "                \"comments\": [\n",
        "                    \"Enhancing the bowling experience with quality dining options.\",\n",
        "                    \"Featuring a menu of favorite foods and craft beverages.\",\n",
        "                    \"Hosting themed food nights and happy hour specials.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Bowling alley maintenance and technology\": {\n",
        "                \"vendors\": [\"PinSet Mechanics\", \"LaneTech Solutions\", \"FrameFix Services\", \"AlleyCare Maintenance\", \"BowlSys Tech\"],\n",
        "                \"comments\": [\n",
        "                    \"Ensuring optimal lane conditions with regular maintenance.\",\n",
        "                    \"Incorporating the latest scoring and pinsetter technology.\",\n",
        "                    \"Offering a seamless experience with well-maintained equipment.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Special events and themed nights\": {\n",
        "                \"vendors\": [\"ThemeBowl Nights\", \"AlleyFest Events\", \"CosmicBowl Parties\", \"RetroRoll Back\", \"GlowPin Evenings\"],\n",
        "                \"comments\": [\n",
        "                    \"Hosting unique themed nights for memorable experiences.\",\n",
        "                    \"Attracting diverse crowds with costume, music, and decade nights.\",\n",
        "                    \"Creating a vibrant and entertaining atmosphere for all ages.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Membership and loyalty programs\": {\n",
        "                \"vendors\": [\"BowlClub Memberships\", \"PinPerks Loyalty\", \"StrikeSavers Club\", \"FrameRewards Program\", \"AlleyAdvantage Benefits\"],\n",
        "                \"comments\": [\n",
        "                    \"Offering exclusive benefits and discounts to members.\",\n",
        "                    \"Building a loyal community with rewards and recognition.\",\n",
        "                    \"Providing special offers and early access to events.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Arcade and additional entertainment\": {\n",
        "                \"vendors\": [\"ArcadeStrike Zone\", \"PinPlay Arcade\", \"AlleyGames Entertainment\", \"Bowl&Play Centers\", \"GameFrame Arcade\"],\n",
        "                \"comments\": [\n",
        "                    \"Complementing bowling with a variety of arcade games.\",\n",
        "                    \"Catering to families and younger guests with diverse entertainment.\",\n",
        "                    \"Regularly updating game selections for fresh experiences.\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"Political Organizations\": {\n",
        "        \"activities\": {\n",
        "            \"Voter education and registration drives\": {\n",
        "                \"vendors\": [\"VoteReady Campaigns\", \"ElectAware Initiatives\", \"DemocracyBoost Org\", \"RegisterNow Networks\", \"CivicDuty Partners\"],\n",
        "                \"comments\": [\n",
        "                    \"Enhancing public awareness on the importance of voting.\",\n",
        "                    \"Facilitating easy access to voter registration resources.\",\n",
        "                    \"Organizing community workshops for informed electoral participation.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Campaign strategy and management\": {\n",
        "                \"vendors\": [\"StrategyPol Consultants\", \"CampaignEdge Solutions\", \"ElectionWin Advisors\", \"PolManage Experts\", \"VoteCraft Strategies\"],\n",
        "                \"comments\": [\n",
        "                    \"Developing comprehensive campaign strategies for candidates.\",\n",
        "                    \"Providing end-to-end campaign management services.\",\n",
        "                    \"Utilizing data analytics for targeted voter outreach.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Political advocacy and lobbying\": {\n",
        "                \"vendors\": [\"AdvocateVoice Group\", \"PolicyPush Lobbyists\", \"ChangeMakers Coalition\", \"ActionAgenda Advocates\", \"CivicInfluence Partners\"],\n",
        "                \"comments\": [\n",
        "                    \"Representing constituent interests at legislative levels.\",\n",
        "                    \"Engaging in policy advocacy for social and political change.\",\n",
        "                    \"Building coalitions for broader impact on public policy.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Fundraising and donor management\": {\n",
        "                \"vendors\": [\"FundFuture Campaigns\", \"DonateWell Services\", \"ElevateFunds Platform\", \"PledgeProspect Initiative\", \"SupporterSync Solutions\"],\n",
        "                \"comments\": [\n",
        "                    \"Implementing effective fundraising strategies for political causes.\",\n",
        "                    \"Managing donor relations and recurring contribution programs.\",\n",
        "                    \"Leveraging digital platforms for campaign financing.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Social media and digital campaigning\": {\n",
        "                \"vendors\": [\"DigitalVoice Campaigns\", \"SocialSphere Strategies\", \"NetInfluence Marketing\", \"OnlineElect Solutions\", \"WebCampaign Creators\"],\n",
        "                \"comments\": [\n",
        "                    \"Maximizing online presence for political campaigns.\",\n",
        "                    \"Engaging voters through targeted social media content.\",\n",
        "                    \"Analyzing digital outreach efforts for optimized engagement.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Issue-based advocacy campaigns\": {\n",
        "                \"vendors\": [\"CauseChampion Org\", \"IssueAdvocates Network\", \"RightFocus Campaigns\", \"UnityVoice Coalition\", \"ActionForChange Group\"],\n",
        "                \"comments\": [\n",
        "                    \"Focusing on key social, environmental, and economic issues.\",\n",
        "                    \"Raising public awareness and support for legislative action.\",\n",
        "                    \"Mobilizing grassroots movements for policy advocacy.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Political event planning and coordination\": {\n",
        "                \"vendors\": [\"EventPolitik Planners\", \"RallyReady Coordinators\", \"DebateStage Organizers\", \"TownHall Productions\", \"ElectEvents Company\"],\n",
        "                \"comments\": [\n",
        "                    \"Organizing rallies, debates, and town hall meetings.\",\n",
        "                    \"Coordinating logistics for large-scale political events.\",\n",
        "                    \"Creating impactful experiences for candidate support and advocacy.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Public relations and media outreach\": {\n",
        "                \"vendors\": [\"MediaMatters Relations\", \"PressPoint Communications\", \"PublicVoice PR\", \"CampaignSpotlight PR\", \"ElectorateEngage Media\"],\n",
        "                \"comments\": [\n",
        "                    \"Managing media relations to shape public perception.\",\n",
        "                    \"Crafting press releases and managing news coverage.\",\n",
        "                    \"Strategizing media outreach to elevate political profiles.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Research and policy analysis\": {\n",
        "                \"vendors\": [\"PolicyInsight Research\", \"ElectAnalytica Thinktank\", \"VoteMetrics Analysis\", \"CivicStudies Institute\", \"StrategySphere Analytics\"],\n",
        "                \"comments\": [\n",
        "                    \"Conducting research to inform policy positions and advocacy.\",\n",
        "                    \"Analyzing electoral trends and voter behavior.\",\n",
        "                    \"Providing strategic insights for campaign and policy development.\"\n",
        "                ]\n",
        "            },\n",
        "            \"Grassroots organizing and mobilization\": {\n",
        "                \"vendors\": [\"GrassrootsEmpower Network\", \"MobilizeAction Group\", \"CommunityVoice Organizers\", \"RootsRise Movements\", \"CivicMobilize Collective\"],\n",
        "                \"comments\": [\n",
        "                    \"Building community networks for political engagement.\",\n",
        "                    \"Empowering volunteers through training and resources.\",\n",
        "                    \"Organizing door-to-door campaigns and local events for voter outreach.\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "hQMy3V2wV5Cp",
        "outputId": "c203eb72-ec36-4345-993e-84210da22eb5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'naics_info' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-952d4b338366>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Assuming naics_info is your structured data for NAICS information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaics_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Split into training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'naics_info' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def generate_record(activity, vendor, cost, comment, naics_title, csv_columns):\n",
        "    \"\"\"\n",
        "    Dynamically generate a record based on the provided parameters and csv_columns.\n",
        "\n",
        "    Parameters:\n",
        "    - activity: The business activity description.\n",
        "    - vendor: The vendor name.\n",
        "    - comment: The comment associated with the activity.\n",
        "    - naics_title: The 2017 NAICS Title.\n",
        "    - csv_columns: List of column names.\n",
        "    - cost: The cost in USD.\n",
        "\n",
        "    Returns:\n",
        "    - A dictionary representing a single record.\n",
        "    \"\"\"\n",
        "    # Initialize record with column names from csv_columns\n",
        "    record = dict.fromkeys(csv_columns, \"\")\n",
        "\n",
        "    # Dynamically assign values to keys based on their order in csv_columns\n",
        "    record[csv_columns[0]] = activity\n",
        "    record[csv_columns[1]] = vendor\n",
        "    record[csv_columns[2]] = cost\n",
        "    record[csv_columns[3]] = comment\n",
        "    record[csv_columns[4]] = naics_title\n",
        "\n",
        "    return record\n",
        "\n",
        "def generate_dataset(naics_info, csv_columns):\n",
        "    records = []\n",
        "    for index in range(10):\n",
        "      for naics_title, details in naics_info.items():\n",
        "          for activity, info in details['activities'].items():\n",
        "              for vendor in info['vendors']:\n",
        "                  for comment in info['comments']:\n",
        "                      # Generating a random cost for each record\n",
        "                      cost_usd = np.random.random() * 1000\n",
        "                      # Generate each record using the updated function\n",
        "                      record = generate_record(activity, vendor, cost_usd, comment, naics_title, csv_columns)\n",
        "                      records.append(record)\n",
        "    return pd.DataFrame(records, columns=csv_columns)\n",
        "\n",
        "# Assuming naics_info is your structured data for NAICS information\n",
        "dataset = generate_dataset(naics_info, csv_columns)\n",
        "\n",
        "# Split into training and test sets\n",
        "train_dataset = dataset.sample(frac=0.833, random_state=42)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "\n",
        "# Save to CSV files\n",
        "# Upload or update the training and test datasets\n",
        "upload_dataframe(drive, folder_id, train_dataset, total_file_name)\n",
        "upload_dataframe(drive, folder_id, train_dataset, train_file_name)\n",
        "upload_dataframe(drive, folder_id, test_dataset, test_file_name)\n",
        "\n",
        "# train_dataset.to_csv(file_folder+'sustainability_business_activities_training.csv', index=False)\n",
        "# test_dataset.to_csv(file_folder+'sustainability_business_activities_test.csv', index=False)\n",
        "\n",
        "print(f\"Dataset generated with {len(train_dataset)} training records, {len(test_dataset)} test records for {len(naics_info.items())} titles.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "WarbNNxu0jSM",
        "outputId": "32ccd055-78e9-4af1-cc00-776eb5b66266"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'drive' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-faf6ec60e3c8>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile_list\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mepa_file_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_file_id_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPA_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mepa_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepa_file_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mepa_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPA_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'drive' is not defined"
          ]
        }
      ],
      "source": [
        "train_file_name = 'sustainability_business_activities_training.csv'\n",
        "test_file_name = 'sustainability_business_activities_test.csv'\n",
        "EPA_file_name = 'EPA_EmissionData.csv'\n",
        "\n",
        "\n",
        "# Define the fields to potentially introduce errors\n",
        "fields = ['Business Activity Description', 'Business Activity Vendor', 'Business Activity Comment']\n",
        "num_max_error_columns = 1\n",
        "naics_title_column_name = '2017 NAICS Title'\n",
        "activity_cost_column_name = 'Business Activity Cost USD'\n",
        "epa_emission_factor_column_name = 'Supply Chain Emission Factors without Margins'\n",
        "separator_string = \" [SEP] \"\n",
        "error_column_append_text = \" Error\"\n",
        "combined_text_column_name = 'combined_text'\n",
        "encoded_label_column_name = 'encoded_labels'\n",
        "\n",
        "demo_mode = True\n",
        "\n",
        "def find_file_id_by_name(drive, folder_id, file_name):\n",
        "    \"\"\"Search for a file by name in the specified Google Drive folder.\"\"\"\n",
        "    query = f\"'{folder_id}' in parents and trashed=false and title='{file_name}'\"\n",
        "    file_list = drive.ListFile({'q': query}).GetList()\n",
        "    return file_list[0]['id'] if file_list else None\n",
        "\n",
        "epa_file_id = find_file_id_by_name(drive, folder_id, EPA_file_name)\n",
        "epa_data = drive.CreateFile({'id': epa_file_id})\n",
        "epa_data.GetContentFile(EPA_file_name)\n",
        "factor_df = pd.read_csv(EPA_file_name)\n",
        "print(f\"{len(factor_df)} of rows in factor csv\")\n",
        "# print(factor_df.head())\n",
        "\n",
        "train_file_id = find_file_id_by_name(drive, folder_id, train_file_name)\n",
        "activity_data = drive.CreateFile({'id': train_file_id})\n",
        "activity_data.GetContentFile(train_file_name)\n",
        "activity_df = pd.read_csv(train_file_name)\n",
        "print(f\"{len(activity_df)} of rows in training csv\")\n",
        "# print(activity_df.head())\n",
        "\n",
        "# Load the test data\n",
        "test_file_id = find_file_id_by_name(drive, folder_id, test_file_name)\n",
        "activity_test_data = drive.CreateFile({'id': test_file_id})\n",
        "activity_test_data.GetContentFile(test_file_name)\n",
        "test_df = pd.read_csv(test_file_name)\n",
        "print(f\"{len(test_df)} of rows in test csv\")\n",
        "# print(test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8CWKpaf16zb"
      },
      "outputs": [],
      "source": [
        "label_dict = {value: idx for idx, value in enumerate(activity_df[naics_title_column_name].unique())}\n",
        "activity_df[encoded_label_column_name] = activity_df[naics_title_column_name].map(label_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZytkNGy2DaB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Helper functions\n",
        "def introduce_minor_errors(text):\n",
        "    \"\"\"Introduce minor spelling mistakes in the text.\"\"\"\n",
        "    errors_introduced = 0\n",
        "    max_errors = random.randint(2, 3)  # Decide to introduce 2 or 3 minor errors\n",
        "\n",
        "    while errors_introduced < max_errors and len(text) > 4:  # Ensure text is long enough to alter\n",
        "        error_type = random.choice(['substitute', 'omit', 'swap'])\n",
        "        error_index = random.randint(1, len(text) - 2)  # Avoid beginning and end of the text for simplicity\n",
        "\n",
        "        if error_type == 'substitute':\n",
        "            # Substitute a character with a nearby character (mimicking common typing errors)\n",
        "            substitutions = {'a': 's', 's': 'a', 'd': 'f', 'i': 'o', 'o': 'p', 'e': 'r', 'r': 't'}\n",
        "            if text[error_index] in substitutions:\n",
        "                text = text[:error_index] + substitutions[text[error_index]] + text[error_index + 1:]\n",
        "                errors_introduced += 1\n",
        "\n",
        "        elif error_type == 'omit':\n",
        "            # Omit a character\n",
        "            text = text[:error_index] + text[error_index + 1:]\n",
        "            errors_introduced += 1\n",
        "\n",
        "        elif error_type == 'swap':\n",
        "            # Swap two adjacent characters\n",
        "            if error_index < len(text) - 1:  # Ensure there's a character to swap with\n",
        "                text = text[:error_index] + text[error_index + 1] + text[error_index] + text[error_index + 2:]\n",
        "                errors_introduced += 1\n",
        "    return text\n",
        "\n",
        "def introduce_major_errors(text):\n",
        "    \"\"\"Replace or scramble parts of the text to introduce major errors.\"\"\"\n",
        "    # Randomly choose between scrambling or inserting irrelevant text\n",
        "    if random.random() < 0.5:\n",
        "        return ''.join(random.sample(text, len(text)))\n",
        "    else:\n",
        "        return \"Irrelevant text \" + ''.join(random.sample(text, len(text)))\n",
        "    return text\n",
        "\n",
        "# Function to randomly apply either minor or major errors to a text\n",
        "def apply_random_error(text):\n",
        "    if random.random() < 0.20:  # 15% chance to introduce an error\n",
        "        #error_type = random.choice(['minor', 'major'])\n",
        "        #if error_type == 'minor':\n",
        "        #    return introduce_minor_errors(text)\n",
        "        #else:\n",
        "            return introduce_major_errors(text)   # only major errors\n",
        "    return text\n",
        "\n",
        "\n",
        "def apply_errors_with_limit(row, fields, max_errors=num_max_error_columns):\n",
        "    \"\"\"\n",
        "    Randomly apply errors to a limited number of fields in a row.\n",
        "\n",
        "    Parameters:\n",
        "    - row: The DataFrame row to apply errors to.\n",
        "    - fields: A list of field names to potentially apply errors to.\n",
        "    - max_errors: Maximum number of fields to apply errors to.\n",
        "    \"\"\"\n",
        "    # Randomly decide how many fields to apply errors to (0 to max_errors)\n",
        "    errors_to_apply = random.randint(0, max_errors)\n",
        "\n",
        "    # Randomly select the fields where errors will be applied\n",
        "    fields_with_errors = random.sample(fields, errors_to_apply)\n",
        "\n",
        "    # Apply errors to the selected fields\n",
        "    for field in fields:\n",
        "        if field in fields_with_errors:\n",
        "            row[field + error_column_append_text] = apply_random_error(row[field])\n",
        "        else:\n",
        "            row[field + error_column_append_text] = row[field]\n",
        "\n",
        "    return row\n",
        "\n",
        "def combine_text_fields(row, fields):\n",
        "    \"\"\"\n",
        "    Combine multiple text fields into a single combined text string.\n",
        "\n",
        "    Parameters:\n",
        "    - row: A DataFrame row containing the text fields.\n",
        "    - fields: A list of field names to be combined.\n",
        "\n",
        "    Returns:\n",
        "    - combined_text: A string containing the combined text from the specified fields.\n",
        "    \"\"\"\n",
        "    combined_parts = []\n",
        "    for field in fields:\n",
        "        # Assuming the 'Error' versions of fields are already in the DataFrame\n",
        "        error_field_name = f\"{field}{error_column_append_text}\"\n",
        "        if error_field_name in row:\n",
        "            field_label = field.replace(\" \", \"_\")  # Replace spaces with underscores for label\n",
        "            combined_parts.append(f\"{field_label}: {row[error_field_name]}\")\n",
        "    combined_text = separator_string.join(combined_parts)\n",
        "    return combined_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3baYLYhJ2IIR",
        "outputId": "57d18c80-0fb8-4e91-ac68-c17f7ee90187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated: train_Mar12.csv\n",
            "Updated: test_Mar12.csv\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "current_date = datetime.now()\n",
        "# Format month as 3-letter abbreviation and day as a number\n",
        "formatted_date = current_date.strftime('%b%d')\n",
        "\n",
        "# Apply errors to 2 or fewer fields for each row\n",
        "activity_df = activity_df.apply(lambda row: apply_errors_with_limit(row, fields), axis=1)\n",
        "# Apply the function to each row of the DataFrame to create the 'combined_text' column\n",
        "activity_df[combined_text_column_name] = activity_df.apply(lambda row: combine_text_fields(row, fields), axis=1)\n",
        "# Now, 'combined_text' contains the concatenated texts with either minor or major errors introduced\n",
        "temp_train_file_name = 'sustainability_business_activities_training_with_bad_errors.csv'\n",
        "\n",
        "# Apply errors to 2 or fewer fields for each row\n",
        "test_df = test_df.apply(lambda row: apply_errors_with_limit(row, fields), axis=1)\n",
        "# Combine the possibly altered text fields into a new 'combined_text' column\n",
        "test_df[combined_text_column_name] = test_df.apply(lambda row: combine_text_fields(row, fields), axis=1)\n",
        "temp_test_file_name = 'sustainability_business_activities_test_with_bad_errors.csv'\n",
        "\n",
        "upload_dataframe(drive, folder_id, activity_df, temp_train_file_name)\n",
        "upload_dataframe(drive, folder_id, test_df, temp_test_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ2_3aqnY-l3",
        "outputId": "43e641e2-67d5-4c1a-af69-fef5b181c50d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated: collected_tweets.txt\n",
            "Uploaded collected_tweets.txt to Google Drive.\n"
          ]
        }
      ],
      "source": [
        "# Convert online datasets into txt file which we can use for finetuning chatpt 2\n",
        "# might need to edit to skip certain tweets/lines\n",
        "# current content that may be negatively influencing are:\n",
        "# links (check if strings longer than 4 lenght start with http)\n",
        "# usernames starting with @\n",
        "# any lines that are non alphabetical chars (e.g # symbols or emojis)\n",
        "\n",
        "\n",
        "# Function to find file IDs by names\n",
        "def find_file_ids_by_names(drive, folder_id, file_names):\n",
        "    file_ids = []\n",
        "    for file_name in file_names:\n",
        "        file_id = find_file_id_by_name(drive, folder_id, file_name)\n",
        "        file_ids.append(file_id)\n",
        "    return file_ids\n",
        "\n",
        "# Function to upload text content to Google Drive\n",
        "def upload_text_content(drive, folder_id, text_content, file_name):\n",
        "    # Check if file exists\n",
        "    file_id = find_file_id_by_name(drive, folder_id, file_name)\n",
        "\n",
        "    if file_id:\n",
        "        # File exists, update the content\n",
        "        file = drive.CreateFile({'id': file_id})\n",
        "        file.SetContentString(text_content)\n",
        "        file.Upload()\n",
        "        print(f\"Updated: {file_name}\")\n",
        "    else:\n",
        "        # File doesn't exist, create a new one\n",
        "        file = drive.CreateFile({'title': file_name, 'parents': [{'id': folder_id}]})\n",
        "        file.SetContentString(text_content)\n",
        "        file.Upload()\n",
        "        print(f\"Created: {file_name}\")\n",
        "\n",
        "# Function to read content from Google Drive\n",
        "def read_text_content_from_drive(drive, file_id):\n",
        "    file = drive.CreateFile({'id': file_id})\n",
        "    file_content = file.GetContentString()\n",
        "    return file_content\n",
        "\n",
        "# Function to process content from Google Drive\n",
        "def process_and_upload_conll_content(drive, folder_id, file_ids, output_file_name):\n",
        "    tweets_content = []\n",
        "\n",
        "    # Process each CoNLL file by file ID\n",
        "    for file_id in file_ids:\n",
        "        file_content = read_text_content_from_drive(drive, file_id)\n",
        "        for line in file_content.splitlines():\n",
        "            columns = line.strip().split()\n",
        "            if columns:\n",
        "                tweets_content.append(columns[0])\n",
        "            else:\n",
        "                tweets_content.append('\\n')\n",
        "\n",
        "    # Convert list to string\n",
        "    text_content = ' '.join(tweets_content)\n",
        "\n",
        "    # Upload collected tweets to Google Drive\n",
        "    upload_text_content(drive, folder_id, text_content, output_file_name)\n",
        "    print(f\"Uploaded {output_file_name} to Google Drive.\")\n",
        "\n",
        "\n",
        "\n",
        "# List of CoNLL file names to process\n",
        "conll_file_names = ['a.conll', 'b.conll', 'c.conll', 'd.conll', 'e.conll', 'f.conll']\n",
        "# Get file IDs for all file names\n",
        "conll_file_ids = find_file_ids_by_names(drive, folder_id, conll_file_names)\n",
        "\n",
        "output_file_name = \"collected_tweets.txt\"\n",
        "\n",
        "# Call the function with your data\n",
        "process_and_upload_conll_content(drive, folder_id, conll_file_ids, output_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rqktZnOY-1f",
        "outputId": "b99fd8b9-d8b8-4399-9b0b-9c54e1bcfa05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m729.8/731.7 MB\u001b[0m \u001b[31m134.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "#chatgpt 2 finetuning. takes less than 10 minutes\n",
        "# also tried neo gpt 2.7 but too compute heavy\n",
        "\n",
        "\n",
        "!pip install torch torchvision\n",
        "!pip install sentence-transformers accelerate -U\n",
        "!pip install transformers[torch] -U\n",
        "!pip install transformers -U\n",
        "!pip install accelerate -U\n",
        "\n",
        "import transformers\n",
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling\n",
        "import accelerate\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from google.colab import drive as dr\n",
        "\n",
        "\n",
        "print(\"Accelerate version:\", accelerate.__version__)\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "\n",
        "\n",
        "dr.mount('/content/drive')\n",
        "finetune_path = '/content/drive/My Drive/224_project/collected_tweets.txt'\n",
        "output_dir = '/content/drive/My Drive//224_project/gpt2_finetuned'\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "\n",
        "## gpt neo 2.7 close to gpt 3 but finetuning is too compute heavy, always fails\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-2.7B')\n",
        "# model = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-2.7B')\n",
        "\n",
        "\n",
        "# Prepare the dataset\n",
        "dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=finetune_path,\n",
        "    block_size=128)  # Maybe adjust block size?\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,  # Maybe adjust epochs?\n",
        "    per_device_train_batch_size=4,  # Can be adjust?\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")\n",
        "\n",
        "# Start fine-tuning\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "147FZOq_Y--V",
        "outputId": "ac7cc9c7-8425-4708-9e94-c2a5a48ec065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows in file: 9\n",
            "Processing row 1/9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing row 2/9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing row 3/9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing row 4/9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing row 5/9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing row 6/9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing row 7/9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing row 8/9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing row 9/9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished processing /content/drive/My Drive/224_project/example.csv. Saved to /content/drive/My Drive/224_project/example_errors.csv.\n"
          ]
        }
      ],
      "source": [
        "# inject errors using chagpt2. tired both finetuned and not finetuned.\n",
        "# also tried gpt 2.7. experiemented with paramters, prompts, no prompts,\n",
        "# but the model is not smart enough to recreate the original cell\n",
        "# content with errors. Given the cell, \"hello world\" regardless of good prompt\n",
        "# preapended or not, it generates \"hello world\" identically mathcing first and\n",
        "# then it can generates errors/language that does not make sense if finetuned\n",
        "# or it just continues the sentence if not finetuned\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, pipeline\n",
        "# import openai\n",
        "from google.colab import drive as dr\n",
        "\n",
        "\n",
        "dr.mount('/content/drive')\n",
        "\n",
        "#openai.api_key = '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'\n",
        "\n",
        "\n",
        "fields = ['Business Activity Description', 'Business Activity Vendor', 'Business Activity Comment']\n",
        "combined_text_column_name = 'combined_text'\n",
        "\n",
        "# Load the fine-tuned gpt2 model for text generation,\n",
        "model_path = '/content/drive/My Drive/224_project/gpt2_finetuned'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "\n",
        "\n",
        "# tried using gpt 2 without finetuning,\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "# model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "\n",
        "\n",
        "## gpt neo 2.7 without finetuning\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-2.7B')\n",
        "# model = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-2.7B')\n",
        "\n",
        "\n",
        "text_generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "prompt = \"\"\"Below are sentences followed by versions with common typing errors,\n",
        "grammatical mistakes, or word misuses that people often make.\n",
        "Please transform the provided sentence in a similar manner by introducing errors:\n",
        "\n",
        "Correct: The quick brown fox jumps over the lazy dog.\n",
        "With errors: Teh quikc brwon fxo jumps oevr teh lazi doog.\n",
        "\n",
        "Correct: I will meet you at the library at 3 PM today.\n",
        "With errors: I wil met yu at teh libary at 3 PM tdoay.\n",
        "\n",
        "Correct: Ensure all documents are organized and submitted by the deadline.\n",
        "With errors: Esnure al documetns are orgnaized and sbmitted by teh deadline.\n",
        "\n",
        "Now, introduce errors into the following sentence: \"\"\"\n",
        "\n",
        "prompt_length = len(tokenizer.encode(prompt))\n",
        "# prompt_chars = len(prompt)\n",
        "\n",
        "\n",
        "def combine_text_fields(row, fields):\n",
        "    return ':'.join([row[field] for field in fields])\n",
        "\n",
        "def introduce_errors_with_gpt2(input_csv_path, output_csv_path, fields):\n",
        "    df = pd.read_csv(input_csv_path)\n",
        "    total_rows = len(df)\n",
        "    print(f\"Total rows in file: {total_rows}\")\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        print(f\"Processing row {index+1}/{total_rows}...\")\n",
        "        for field in fields:\n",
        "            original_text = row[field]\n",
        "            buffer = 0\n",
        "            text_length = len(tokenizer.encode(original_text))\n",
        "            max_length = min( (2 * text_length) + prompt_length + buffer, tokenizer.model_max_length)\n",
        "\n",
        "            curr = prompt + original_text\n",
        "\n",
        "            # Played with these parameters\n",
        "            generated_text_with_errors = text_generator(curr,\n",
        "                                            max_length=max_length,  # Consider reducing max_length\n",
        "                                            temperature=1,  # Increase temperature for creativity\n",
        "                                            top_k=40,  # Adjust for diversity\n",
        "                                            top_p=0.9,  # Nucleus sampling for coherent yet diverse output\n",
        "                                            num_return_sequences=1)[0]['generated_text'].strip()\n",
        "\n",
        "\n",
        "            # tried to use gpt 3, not free\n",
        "\n",
        "            # # Generate a completion using the OpenAI API\n",
        "            # response = openai.Completion.create(\n",
        "            #   model=\"gpt-3.5-turbo\",\n",
        "            #   prompt=curr_prompt,\n",
        "            #   max_tokens=20  # Adjust the number of maximum tokens as needed\n",
        "            # )\n",
        "\n",
        "\n",
        "             # Remove prompt from output, currently not working, length not being calculated correctlty but simple problem to fix\n",
        "            # generated_text_with_errors =  generated_text_with_errors[prompt lenght + text length:]\n",
        "\n",
        "            df.at[index, field] = generated_text_with_errors\n",
        "\n",
        "\n",
        "    # Apply the function to each row of the DataFrame to create the 'combined_text' column\n",
        "    df[combined_text_column_name] = df.apply(lambda row: combine_text_fields(row, fields), axis=1)\n",
        "\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Finished processing {input_csv_path}. Saved to {output_csv_path}.\")\n",
        "\n",
        "\n",
        "# for debugging\n",
        "input_csv_path = '/content/drive/My Drive/224_project/example.csv'\n",
        "errors_csv_path = '/content/drive/My Drive/224_project/example_errors.csv'\n",
        "introduce_errors_with_gpt2(input_csv_path, errors_csv_path, fields)\n",
        "\n",
        "# test\n",
        "# input_csv_path_test = '/content/drive/My Drive/224_project/sustainability_business_activities_test.csv'\n",
        "# errors_csv_path_test = '/content/drive/My Drive/224_project/sustainability_business_activities_test_with_errors.csv'\n",
        "# introduce_errors_with_gpt2(input_csv_path_test, errors_csv_path_test, fields)\n",
        "\n",
        "# training\n",
        "# input_csv_path_train = '/content/drive/My Drive/224_project/sustainability_business_activities_training.csv'\n",
        "# errors_csv_path_train = '/content/drive/My Drive/224_project/sustainability_business_activities_training_with_errors.csv'\n",
        "# introduce_errors_with_gpt2(input_csv_path_train, errors_csv_path_train, fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wZJ9OoQrY_Hc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "outputId": "0baebdda-0263-474f-9e0e-0b49491b6099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 18869\n",
            "-rw------- 1 root root   59961 Mar 17 02:22  accuracy_vs_error_rate_20240317.png\n",
            "-rw------- 1 root root  121889 Mar 12 20:56  a.conll\n",
            "-rw------- 1 root root  235519 Mar 12 20:36  b.conll\n",
            "-rw------- 1 root root  758474 Mar 12 21:42  cached_lm_GPT2Tokenizer_128_collected_tweets.txt\n",
            "-rw------- 1 root root       0 Mar 13 19:12  cached_lm_GPT2Tokenizer_128_collected_tweets.txt.lock\n",
            "-rw------- 1 root root   34631 Mar 12 20:36  c.conll\n",
            "-rw------- 1 root root  875834 Mar 12 21:27  collected_tweets.txt\n",
            "-rw------- 1 root root  320339 Mar 12 20:36  d.conll\n",
            "-rw------- 1 root root  294166 Mar 12 20:36  e.conll\n",
            "-rw------- 1 root root  123247 Mar 12 04:06  EPA_EmissionData.csv\n",
            "-rw------- 1 root root    1512 Mar 13 05:00  example.csv\n",
            "-rw------- 1 root root   38804 Mar 13 20:27  example_errors.csv\n",
            "-rw------- 1 root root  235158 Mar 12 20:36  f.conll\n",
            "drwx------ 2 root root    4096 Mar 12 22:25  gpt2_finetuned\n",
            "-rw------- 1 root root 2858223 Mar 17 01:31  movies.csv\n",
            "-rw------- 1 root root  123247 Mar 14 06:48 'SupplyChainGHGEmissionFactors_v1.2_NAICS_CO2e_USD2021 (3).csv'\n",
            "-rw------- 1 root root 2105539 Mar 12 21:03  sustainability_business_activities.csv\n",
            "-rw------- 1 root root  423469 Mar 12 21:03  sustainability_business_activities_test.csv\n",
            "-rw------- 1 root root 1277840 Mar 13 01:26  sustainability_business_activities_test_with_bad_errors.csv\n",
            "-rw------- 1 root root  923381 Mar 13 00:43  sustainability_business_activities_test_with_errors.csv\n",
            "-rw------- 1 root root 2105539 Mar 12 21:03  sustainability_business_activities_training.csv\n",
            "-rw------- 1 root root 6396214 Mar 13 01:26  sustainability_business_activities_training_with_bad_errors.csv\n",
            "Summary statistics saved to /content/drive/My Drive/224n_project/similarity_scores_test_summary.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/224n_project/sustainability_business_activities_training_with_errors.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0422e0f6158a>\u001b[0m in \u001b[0;36m<cell line: 85>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0merrors_csv_path_gpt2_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/224n_project/sustainability_business_activities_training_with_errors.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0moutput_csv_path_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/224n_project/similarity_scores_test.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mscore_text_similarity_and_save_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_csv_path_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors_csv_path_gpt2_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors_csv_path_probability_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_csv_path_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-0422e0f6158a>\u001b[0m in \u001b[0;36mscore_text_similarity_and_save_summary\u001b[0;34m(original_csv_path, errors_csv_path_gpt2, errors_csv_path_probability, output_csv_path, fields)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore_text_similarity_and_save_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors_csv_path_gpt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors_csv_path_probability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moriginal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_csv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0merrors_df_gpt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors_csv_path_gpt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0merrors_df_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors_csv_path_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/224n_project/sustainability_business_activities_training_with_errors.csv'"
          ]
        }
      ],
      "source": [
        "# Model to classify how similar error files is to orginal file before errors.\n",
        "# can compare good errors, bad errors, and original. a good score is a high score\n",
        "# in similarity. it reflects how close the errors are to the original,\n",
        "# which reflects human like errors that are similar to the original intented text\n",
        "# I was not able to run this yet, never got to this part.\n",
        "\n",
        "# !pip install sentence-transformers\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "!ls -l \"/content/drive/My Drive/224n_project/\"\n",
        "\n",
        "\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def score_text_similarity_and_save_summary(original_csv_path, errors_csv_path_gpt2, errors_csv_path_probability, output_csv_path, fields):\n",
        "    original_df = pd.read_csv(original_csv_path)\n",
        "    errors_df_gpt2 = pd.read_csv(errors_csv_path_gpt2)\n",
        "    errors_df_probability = pd.read_csv(errors_csv_path_probability)\n",
        "\n",
        "    results_df = original_df.copy().drop(fields, axis=1)  # Drop original fields to avoid confusion in the results\n",
        "\n",
        "    total_scores_gpt2, total_scores_probability = [], []\n",
        "\n",
        "    for index in range(len(original_df)):\n",
        "        for field in fields:\n",
        "            original_text = original_df.at[index, field]\n",
        "            modified_text_gpt2 = errors_df_gpt2.at[index, field]\n",
        "            modified_text_probability = errors_df_probability.at[index, field]\n",
        "\n",
        "            original_vector = model.encode(original_text, convert_to_tensor=True)\n",
        "            modified_vector_gpt2 = model.encode(modified_text_gpt2, convert_to_tensor=True)\n",
        "            modified_vector_probability = model.encode(modified_text_probability, convert_to_tensor=True)\n",
        "\n",
        "            similarity_gpt2 = util.pytorch_cos_sim(original_vector, modified_vector_gpt2)\n",
        "            similarity_probability = util.pytorch_cos_sim(original_vector, modified_vector_probability)\n",
        "\n",
        "            total_scores_gpt2.append(similarity_gpt2.item())\n",
        "            total_scores_probability.append(similarity_probability.item())\n",
        "\n",
        "            results_df.at[index, f'{field}_GPT2_SimilarityScore'] = similarity_gpt2.item()\n",
        "            results_df.at[index, f'{field}_Probability_SimilarityScore'] = similarity_probability.item()\n",
        "\n",
        "    # Save detailed similarity scores\n",
        "    results_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "    # Calculate and save summary statistics\n",
        "    total_gpt2 = sum(total_scores_gpt2)\n",
        "    average_gpt2 = total_gpt2 / len(total_scores_gpt2)\n",
        "    total_probability = sum(total_scores_probability)\n",
        "    average_probability = total_probability / len(total_scores_probability)\n",
        "\n",
        "    summary_data = {\n",
        "        'Total_GPT2_SimilarityScore': total_gpt2,\n",
        "        'Average_GPT2_SimilarityScore': average_gpt2,\n",
        "        'Total_Probability_SimilarityScore': total_probability,\n",
        "        'Average_Probability_SimilarityScore': average_probability\n",
        "    }\n",
        "\n",
        "    summary_df = pd.DataFrame([summary_data])\n",
        "    summary_path = output_csv_path.replace('.csv', '_summary.csv')\n",
        "    summary_df.to_csv(summary_path, index=False)\n",
        "    print(f\"Summary statistics saved to {summary_path}\")\n",
        "\n",
        "\n",
        "fields = ['Business Activity Description', 'Business Activity Vendor', 'Business Activity Comment']\n",
        "\n",
        "original_csv_path_test = '/content/drive/My Drive/224n_project/sustainability_business_activities_test.csv'\n",
        "errors_csv_path_gpt2_test = '/content/drive/My Drive/224n_project/sustainability_business_activities_test_with_errors.csv'\n",
        "errors_csv_path_probability_test = '/content/drive/My Drive/224n_project/sustainability_business_activities_test_with_bad_errors.csv'\n",
        "output_csv_path_test = '/content/drive/My Drive/224n_project/similarity_scores_test.csv'\n",
        "\n",
        "score_text_similarity_and_save_summary(original_csv_path_test, errors_csv_path_gpt2_test, errors_csv_path_probability_test, output_csv_path_test, fields)\n",
        "\n",
        "# original_csv_path_training = '/content/drive/My Drive/224n_project/sustainability_business_activities_training.csv'\n",
        "# errors_csv_path_probability_training = '/content/drive/My Drive/224n_project/sustainability_business_activities_training_with_bad_errors.csv'\n",
        "# errors_csv_path_gpt2_training = '/content/drive/My Drive/224n_project/sustainability_business_activities_training_with_errors.csv'\n",
        "# output_csv_path_training = '/content/drive/My Drive/224n_project/similarity_scores_test.csv'\n",
        "# score_text_similarity_and_save_summary(original_csv_path_training, errors_csv_path_gpt2_training, errors_csv_path_probability_training, output_csv_path_training, fields)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1eaoOa7aIR-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBJqwYuh38RH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Split data into features and labels\n",
        "# activity_df['combined_text'] = activity_df['Business Activity Description'] + \" \" + activity_df['Vendor'] + \" \" + activity_df['Comment']\n",
        "X = activity_df[combined_text_column_name]  # Feature\n",
        "y = activity_df[encoded_label_column_name]  # Assuming 'label' is already encoded as numeric labels"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}